{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг своими руками\n",
    "\n",
    "**Внимание:** в тексте задания произошли изменения - поменялось число деревьев (теперь 50), правило изменения величины шага в задании 3 и добавился параметр `random_state` у решающего дерева. Правильные ответы не поменялись, но теперь их проще получить. Также исправлена опечатка в функции `gbm_predict`.\n",
    "\n",
    "В этом задании будет использоваться датасет `boston` из `sklearn.datasets`. Оставьте последние 25% объектов для контроля качества, разделив `X` и `y` на `X_train`, `y_train` и `X_test`, `y_test`.\n",
    "\n",
    "Целью задания будет реализовать простой вариант градиентного бустинга над регрессионными деревьями для случая квадратичной функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (379, 13) (127, 13) (379,) (127,)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "\n",
    "def my_split(x, frac):\n",
    "    return x[0 : int(round(x.shape[0]-(x.shape[0]*frac)-1))], x[- int(round(x.shape[0]*frac)) :]\n",
    "\n",
    "X, y = sklearn.datasets.load_boston(return_X_y = True)\n",
    "\n",
    "X_train, X_test = my_split(X, 0.25)\n",
    "y_train, y_test = my_split(y, 0.25)\n",
    "\n",
    "print X.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t = np.array([1,2,3,4,5,6,7,8,9,10]) #np.ones(10)\n",
    "#t[-5:]\n",
    "my_split(t, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "\n",
    "Как вы уже знаете из лекций, **бустинг** - это метод построения композиций базовых алгоритмов с помощью последовательного добавления к текущей композиции нового алгоритма с некоторым коэффициентом. \n",
    "\n",
    "Градиентный бустинг обучает каждый новый алгоритм так, чтобы он приближал антиградиент ошибки по ответам композиции на обучающей выборке. Аналогично минимизации функций методом градиентного спуска, в градиентном бустинге мы подправляем композицию, изменяя алгоритм в направлении антиградиента ошибки.\n",
    "\n",
    "Воспользуйтесь формулой из лекций, задающей ответы на обучающей выборке, на которые нужно обучать новый алгоритм (фактически это лишь чуть более подробно расписанный градиент от ошибки), и получите частный ее случай, если функция потерь `L` - квадрат отклонения ответа композиции `a(x)` от правильного ответа `y` на данном `x`.\n",
    "\n",
    "Если вы давно не считали производную самостоятельно, вам поможет таблица производных элементарных функций (которую несложно найти в интернете) и правило дифференцирования сложной функции. После дифференцирования квадрата у вас возникнет множитель 2 — т.к. нам все равно предстоит выбирать коэффициент, с которым будет добавлен новый базовый алгоритм, проигноируйте этот множитель при дальнейшем построении алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Компоненты вектора сдвигов s, фактически, являются теми значениями, которые на объектах обучающей\n",
    "выборки должен принимать новый алгоритм b N (x), чтобы минимизировать ошибку строящейся композиции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ? думаю как то так\n",
    "def L_anti_gradient(a_compose_x, y):\n",
    "    return -(a_compose_x - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "\n",
    "Заведите массив для объектов `DecisionTreeRegressor` (будем их использовать в качестве базовых алгоритмов) и для вещественных чисел (это будут коэффициенты перед базовыми алгоритмами). \n",
    "\n",
    "В цикле от обучите последовательно 50 решающих деревьев с параметрами `max_depth=5` и `random_state=42` (остальные параметры - по умолчанию). В бустинге зачастую используются сотни и тысячи деревьев, но мы ограничимся 50, чтобы алгоритм работал быстрее, и его было проще отлаживать (т.к. цель задания разобраться, как работает метод). Каждое дерево должно обучаться на одном и том же множестве объектов, но ответы, которые учится прогнозировать дерево, будут меняться в соответствие с полученным в задании 1 правилом. \n",
    "\n",
    "Попробуйте для начала всегда брать коэффициент равным 0.9. Обычно оправдано выбирать коэффициент значительно меньшим - порядка 0.05 или 0.1, но т.к. в нашем учебном примере на стандартном датасете будет всего 50 деревьев, возьмем для начала шаг побольше.\n",
    "\n",
    "В процессе реализации обучения вам потребуется функция, которая будет вычислять прогноз построенной на данный момент композиции деревьев на выборке `X`:\n",
    "\n",
    "```\n",
    "def gbm_predict(X):\n",
    "    return [sum([coeff * algo.predict([x])[0] for algo, coeff in zip(base_algorithms_list, coefficients_list)]) for x in X]\n",
    "(считаем, что base_algorithms_list - список с базовыми алгоритмами, coefficients_list - список с коэффициентами перед алгоритмами)\n",
    "```\n",
    "\n",
    "Эта же функция поможет вам получить прогноз на контрольной выборке и оценить качество работы вашего алгоритма с помощью `mean_squared_error` в `sklearn.metrics`. \n",
    "\n",
    "Возведите результат в степень 0.5, чтобы получить `RMSE`. Полученное значение `RMSE` — **ответ в пункте 2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "a1 = np.ones(3)\n",
    "a2 = np.ones(3)\n",
    "#a1 = a1 * 2\n",
    "a2 += (a1 * 2)\n",
    "\n",
    "print a2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "\n",
    "def gbm_predict(X):\n",
    "    return [sum([coeff * algo.predict([x])[0] \n",
    "                for algo, coeff in zip(base_algorithms_list, coefficients_list)]) \n",
    "                    for x in X]\n",
    "\n",
    "base_algorithms_list = []\n",
    "coefficients_list = []\n",
    "\n",
    "#s = np.copy(y_train)\n",
    "#s.fill(np.average(y_train))\n",
    "s = np.zeros(X_train.shape[0]) # initial zeros for shift vector\n",
    "a_x = np.zeros(y_train.shape[0]) # current compose tree results \n",
    "step = 0.9\n",
    "for _ in range(50):\n",
    "    dtr = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "    bn = dtr.fit(X=X_train, y=s)\n",
    "    predict = bn.predict(X_train)\n",
    "    #predict = gbm_predict(X_train)\n",
    "    base_algorithms_list.append(bn)\n",
    "    coefficients_list.append(step)\n",
    "    a_x += (step * predict)\n",
    "    #print a_x\n",
    "    s = L_anti_gradient(a_x, y_train)\n",
    "    #s = (y_train - a_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.47676640788\n",
      "14.078745247 10.2\n",
      "15.4880976115 10.4\n",
      "14.13632885 10.9\n",
      "15.7064544345 11.3\n",
      "15.1146862828 12.3\n",
      "17.0787749535 8.8\n",
      "15.3631749426 7.2\n",
      "15.3729041713 10.5\n",
      "17.7415460401 7.4\n",
      "15.4137905544 10.2\n",
      "14.4572274408 11.5\n",
      "15.774205085 15.1\n",
      "18.3124522955 23.2\n",
      "15.4141336491 9.7\n",
      "21.6591141543 13.8\n",
      "16.375481611 12.7\n",
      "14.9991717157 13.1\n",
      "14.063418423 12.5\n",
      "15.1561422744 8.5\n",
      "16.0665248014 5.0\n",
      "17.7796344988 6.3\n",
      "15.7366563619 5.6\n",
      "13.8771683882 7.2\n",
      "14.0740418206 12.1\n",
      "15.4424048415 8.3\n",
      "16.8705777968 8.5\n",
      "16.2998208037 5.0\n",
      "14.1027131994 11.9\n",
      "21.4900972017 27.9\n",
      "14.901850611 17.2\n",
      "13.8817201666 27.5\n",
      "21.8635510503 15.0\n",
      "13.1161433024 17.2\n",
      "14.9037800586 17.9\n",
      "14.9499040043 16.3\n",
      "14.8743231648 7.0\n",
      "13.1473719427 7.2\n",
      "13.7630322072 7.5\n",
      "17.1519305656 10.4\n",
      "15.0698139546 8.8\n",
      "16.2580113318 8.4\n",
      "19.3348561756 16.7\n",
      "19.77509599 14.2\n",
      "22.1489304942 20.8\n",
      "15.8342418844 13.4\n",
      "19.7699758041 11.7\n",
      "15.0990252378 8.3\n",
      "23.5044005151 10.2\n",
      "22.9187369305 10.9\n",
      "16.8446344021 11.0\n",
      "13.0454600079 9.5\n",
      "16.1133748811 14.5\n",
      "14.0291511228 14.1\n",
      "25.8378427919 16.1\n",
      "16.6044410696 14.3\n",
      "20.9566850761 11.7\n",
      "13.8896089959 13.4\n",
      "13.5871113071 9.6\n",
      "14.8080834222 8.7\n",
      "16.1781407238 8.4\n",
      "17.2615027299 12.8\n",
      "16.1396263745 10.5\n",
      "15.5464300544 17.1\n",
      "15.183814209 18.4\n",
      "15.6872592652 15.4\n",
      "15.4452486324 10.8\n",
      "14.0214260459 11.8\n",
      "15.3445935871 14.9\n",
      "16.6883609971 12.6\n",
      "15.8379227715 14.1\n",
      "15.4690391419 13.0\n",
      "15.4467664064 13.4\n",
      "16.3889911685 15.2\n",
      "16.3629866321 16.1\n",
      "31.2376991084 17.8\n",
      "14.1986880039 14.9\n",
      "16.4766523756 14.1\n",
      "17.2034728846 12.7\n",
      "18.5700132429 13.5\n",
      "16.6744840357 14.9\n",
      "22.0395477523 20.0\n",
      "15.7505755519 16.4\n",
      "22.0087193061 17.7\n",
      "22.1226631405 19.5\n",
      "23.1903159949 20.2\n",
      "24.5771390669 21.4\n",
      "22.809229589 19.9\n",
      "16.9378488157 19.0\n",
      "15.1926191066 19.1\n",
      "19.7417457596 19.1\n",
      "23.8457182436 20.1\n",
      "16.7608640077 19.9\n",
      "23.6427805875 19.6\n",
      "23.1381644068 23.2\n",
      "36.1703306853 29.8\n",
      "15.8395923441 13.8\n",
      "15.2388010751 13.3\n",
      "15.3204487146 16.7\n",
      "15.728554318 12.0\n",
      "17.061597925 14.6\n",
      "24.3044115941 21.4\n",
      "24.5037655884 23.0\n",
      "29.8129550143 23.7\n",
      "33.9856807369 25.0\n",
      "22.9687723244 21.8\n",
      "23.7421744942 20.6\n",
      "22.7548450212 21.2\n",
      "24.6215048619 19.1\n",
      "23.4429818584 20.6\n",
      "18.5103003184 15.2\n",
      "15.3205262423 7.0\n",
      "14.9006104179 8.1\n",
      "16.201080082 13.6\n",
      "17.4154907111 20.1\n",
      "19.5681632576 21.8\n",
      "17.7520727107 24.5\n",
      "18.7296539355 23.1\n",
      "20.9914281727 19.7\n",
      "20.2475848341 18.3\n",
      "19.74908744 21.2\n",
      "20.5000558131 17.5\n",
      "20.0114724407 16.8\n",
      "29.2190434903 22.4\n",
      "17.7669532171 20.6\n",
      "30.1118576078 23.9\n",
      "31.1578648761 22.0\n",
      "17.2069369776 11.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#print a_x.shape, len(base_algorithms_list), len(coefficients_list) \n",
    "y_pred = gbm_predict(X_test)\n",
    "\n",
    "answer1 = (mean_squared_error(y_test, y_pred)) ** 0.5\n",
    "print answer1\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    print y_pred[i], y_test[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def gbm_predict(X):\n",
    "    return [sum([coeff * algo.predict([x])[0] for algo, coeff in zip(base_algorithm, coeffs)]) for x in X]\n",
    "\n",
    "base_algorithm=[]\n",
    "coeffs=[]\n",
    "s = y_train\n",
    "for i in range(50):\n",
    "    clf=DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "    clf.fit(X=X_train, y=s)\n",
    "    base_algorithm.append(clf)\n",
    "    coeffs.append(0.9)\n",
    "    s=y_train-gbm_predict(X_train)\n",
    "    \n",
    "error=mean_squared_error(y_test, gbm_predict(X_test))\n",
    "rmse=error**0.5\n",
    "print rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Вас может также беспокоить, что двигаясь с постоянным шагом, вблизи минимума ошибки ответы на обучающей выборке меняются слишком резко, перескакивая через минимум. \n",
    "\n",
    "Попробуйте уменьшать вес перед каждым алгоритмом с каждой следующей итерацией по формуле `0.9 / (1.0 + i)`, где `i` - номер итерации (от 0 до 49). Используйте качество работы алгоритма как **ответ в пункте 3**. \n",
    "\n",
    "В реальности часто применяется следующая стратегия выбора шага: как только выбран алгоритм, подберем коэффициент перед ним численным методом оптимизации таким образом, чтобы отклонение от правильных ответов было минимальным. Мы не будем предлагать вам реализовать это для выполнения задания, но рекомендуем попробовать разобраться с такой стратегией и реализовать ее при случае для себя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_algorithms_list = []\n",
    "coefficients_list = []\n",
    "\n",
    "s = np.zeros(X_train.shape[0]) # initial zeros for shift vector\n",
    "a_x = np.zeros(y_train.shape[0]) # current compose tree results \n",
    "\n",
    "for i in range(50):\n",
    "    step = 0.9/(1.0+i+1) \n",
    "    dtr = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "    bn = dtr.fit(X=X_train, y=s)\n",
    "    predict = bn.predict(X_train)\n",
    "    base_algorithms_list.append(bn)\n",
    "    coefficients_list.append(step)\n",
    "    a_x += (step * predict)\n",
    "    s = L_anti_gradient(a_x, y_train)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.49731975575\n",
      "14.0550835319 10.2\n",
      "14.4192013339 10.4\n",
      "13.8266468326 10.9\n",
      "13.9356743213 11.3\n",
      "13.9356743213 12.3\n",
      "15.3156960485 8.8\n",
      "13.9009512424 7.2\n",
      "13.8198411964 10.5\n",
      "14.7589946152 7.4\n",
      "14.6624906942 10.2\n",
      "13.9356743213 11.5\n",
      "14.9460211925 15.1\n",
      "15.1538117875 23.2\n",
      "13.9356743213 9.7\n",
      "17.2265055827 13.8\n",
      "14.8832797798 12.7\n",
      "15.5318818297 13.1\n",
      "16.9829595958 12.5\n",
      "14.738672593 8.5\n",
      "13.8198411964 5.0\n",
      "16.8091395344 6.3\n",
      "13.5858952643 5.6\n",
      "13.6952193587 7.2\n",
      "14.5464302116 12.1\n",
      "13.9929215589 8.3\n",
      "15.105788335 8.5\n",
      "14.6003153094 5.0\n",
      "14.4019668659 11.9\n",
      "21.1800482618 27.9\n",
      "14.8267750436 17.2\n",
      "17.6378670849 27.5\n",
      "30.794752994 15.0\n",
      "13.6290689722 17.2\n",
      "14.1327803462 17.9\n",
      "14.9651323272 16.3\n",
      "14.1327803462 7.0\n",
      "13.7172461746 7.2\n",
      "15.5189813826 7.5\n",
      "14.8466294163 10.4\n",
      "14.0327588019 8.8\n",
      "16.2355648669 8.4\n",
      "17.6139403157 16.7\n",
      "17.6827539154 14.2\n",
      "18.3337934588 20.8\n",
      "14.2451456642 13.4\n",
      "15.8996853154 11.7\n",
      "13.4308592264 8.3\n",
      "18.0131192465 10.2\n",
      "18.2177170137 10.9\n",
      "15.7874659651 11.0\n",
      "13.7172461746 9.5\n",
      "14.7173155758 14.5\n",
      "18.1122536743 14.1\n",
      "20.2853267164 16.1\n",
      "14.71543523 14.3\n",
      "16.9088762849 11.7\n",
      "13.7202193431 13.4\n",
      "14.5229327117 9.6\n",
      "13.6784542621 8.7\n",
      "14.6182393757 8.4\n",
      "14.0781688669 12.8\n",
      "14.6325309619 10.5\n",
      "14.3542432219 17.1\n",
      "15.3974373288 18.4\n",
      "16.5368182452 15.4\n",
      "14.2248754682 10.8\n",
      "13.9515146445 11.8\n",
      "15.5935371013 14.9\n",
      "15.3974373288 12.6\n",
      "14.6858815704 14.1\n",
      "17.6997259479 13.0\n",
      "16.1389286943 13.4\n",
      "15.3405551406 15.2\n",
      "15.6337382312 16.1\n",
      "22.8873947782 17.8\n",
      "15.8645387064 14.9\n",
      "14.442925588 14.1\n",
      "15.4743149495 12.7\n",
      "16.0056594832 13.5\n",
      "15.5135299775 14.9\n",
      "17.3474475033 20.0\n",
      "16.7412018391 16.4\n",
      "17.7471721623 17.7\n",
      "19.3587432235 19.5\n",
      "21.0298273959 20.2\n",
      "20.5932133393 21.4\n",
      "19.1209053638 19.9\n",
      "14.3123075401 19.0\n",
      "14.4583846107 19.1\n",
      "16.1727914559 19.1\n",
      "18.4031392426 20.1\n",
      "15.2169310513 19.9\n",
      "19.8669840148 19.6\n",
      "19.9341359032 23.2\n",
      "25.1075132806 29.8\n",
      "14.9607616938 13.8\n",
      "14.4119857108 13.3\n",
      "15.123047341 16.7\n",
      "14.3179061849 12.0\n",
      "15.123047341 14.6\n",
      "19.7739532981 21.4\n",
      "20.9643254559 23.0\n",
      "29.8134512297 23.7\n",
      "27.7982161723 25.0\n",
      "19.7302545059 21.8\n",
      "19.8292605045 20.6\n",
      "21.3716027281 21.2\n",
      "19.1064327889 19.1\n",
      "20.4859879851 20.6\n",
      "16.7195446304 15.2\n",
      "15.3451484369 7.0\n",
      "15.310425358 8.1\n",
      "17.1774937044 13.6\n",
      "18.7091561757 20.1\n",
      "18.6916030406 21.8\n",
      "19.5563097822 24.5\n",
      "18.1421602751 23.1\n",
      "17.9653083722 19.7\n",
      "18.9259373442 18.3\n",
      "19.8753266319 21.2\n",
      "18.5130350607 17.5\n",
      "19.5418011133 16.8\n",
      "25.1332088244 22.4\n",
      "20.7717031257 20.6\n",
      "27.5605273363 23.9\n",
      "26.8421068403 22.0\n",
      "20.1213921158 11.9\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm_predict(X_test)\n",
    "\n",
    "answer1 = (mean_squared_error(y_test, y_pred)) ** 0.5\n",
    "print answer1\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    print y_pred[i], y_test[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "\n",
    "Реализованный вами метод - градиентный бустинг над деревьями - очень популярен в машинном обучении. Он представлен как в самой библиотеке `sklearn`, так и в сторонней библиотеке `XGBoost`, которая имеет свой питоновский интерфейс. На практике `XGBoost` работает заметно лучше `GradientBoostingRegressor` из `sklearn`, но для этого задания вы можете использовать любую реализацию. \n",
    "\n",
    "Исследуйте, переобучается ли градиентный бустинг с ростом числа итераций (и подумайте, почему), а также с ростом глубины деревьев. На основе наблюдений выпишите через пробел номера правильных из приведенных ниже утверждений в порядке возрастания номера (это будет **ответ в п.4**):\n",
    "\n",
    "    1. С увеличением числа деревьев, начиная с некоторого момента, качество работы градиентного бустинга не меняется существенно.\n",
    "\n",
    "    2. С увеличением числа деревьев, начиная с некоторого момента, градиентный бустинг начинает переобучаться.\n",
    "\n",
    "    3. С ростом глубины деревьев, начиная с некоторого момента, качество работы градиентного бустинга на тестовой выборке начинает ухудшаться.\n",
    "\n",
    "    4. С ростом глубины деревьев, начиная с некоторого момента, качество работы градиентного бустинга перестает существенно изменяться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sigor/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/sigor/anaconda2/lib/python2.7/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sigor/anaconda2/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['step']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble , cross_validation, learning_curve, metrics \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9 ,  0.89,  0.88,  0.87,  0.86,  0.85,  0.84,  0.83,  0.82,\n",
       "        0.81,  0.8 ,  0.79,  0.78,  0.77,  0.76,  0.75,  0.74,  0.73,\n",
       "        0.72,  0.71,  0.7 ,  0.69,  0.68,  0.67,  0.66,  0.65,  0.64,\n",
       "        0.63,  0.62,  0.61,  0.6 ,  0.59,  0.58,  0.57,  0.56,  0.55,\n",
       "        0.54,  0.53,  0.52,  0.51,  0.5 ,  0.49,  0.48,  0.47,  0.46,\n",
       "        0.45,  0.44,  0.43,  0.42,  0.41,  0.4 ,  0.39,  0.38,  0.37,\n",
       "        0.36,  0.35,  0.34,  0.33,  0.32,  0.31,  0.3 ,  0.29,  0.28,\n",
       "        0.27,  0.26,  0.25,  0.24,  0.23,  0.22,  0.21,  0.2 ,  0.19,\n",
       "        0.18,  0.17,  0.16,  0.15,  0.14,  0.13,  0.12,  0.11,  0.1 ,\n",
       "        0.09,  0.08,  0.07,  0.06,  0.05,  0.04,  0.03,  0.02])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = np.array(range(-90, -1))*-0.01\n",
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://xgboost.readthedocs.io/en/latest/python/python_api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 208 ms, total: 15 s\n",
      "Wall time: 3.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_scoring = []\n",
    "trees = 50\n",
    "for step in steps:\n",
    "    estimator = xgb.XGBRegressor(n_estimators=trees, learning_rate=step, max_depth=5, min_child_weight=3)\n",
    "    score = cross_validation.cross_val_score(estimator, X, y, scoring='r2', cv=3)\n",
    "    xgb_scoring.append(score)\n",
    "xgb_scoring = np.asmatrix(xgb_scoring)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 10,\n",
       " 15,\n",
       " 20,\n",
       " 25,\n",
       " 30,\n",
       " 35,\n",
       " 40,\n",
       " 45,\n",
       " 50,\n",
       " 55,\n",
       " 60,\n",
       " 65,\n",
       " 70,\n",
       " 75,\n",
       " 80,\n",
       " 85,\n",
       " 90,\n",
       " 95,\n",
       " 100,\n",
       " 105,\n",
       " 110,\n",
       " 115,\n",
       " 120,\n",
       " 125,\n",
       " 130,\n",
       " 135,\n",
       " 140,\n",
       " 145,\n",
       " 150]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trees = [1] + range(10, 155, 5) \n",
    "n_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b5863c87a38f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"xgb_scoring_2 = []\\nfor tree in trees:\\n    estimator = xgb.XGBRegressor(n_estimators=tree, learning_rate=0.01, max_depth=5, min_child_weight=3)\\n    score = cross_validation.cross_val_score(estimator, X, y, scoring='r2', cv=3)\\n    xgb_scoring_2.append(score)\\nxgb_scoring_2 = np.asmatrix(xgb_scoring)    \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sigor/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/sigor/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sigor/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_scoring_2 = []\n",
    "for tree in trees:\n",
    "    estimator = xgb.XGBRegressor(n_estimators=tree, learning_rate=0.01, max_depth=5, min_child_weight=3)\n",
    "    score = cross_validation.cross_val_score(estimator, X, y, scoring='r2', cv=3)\n",
    "    xgb_scoring_2.append(score)\n",
    "xgb_scoring_2 = np.asmatrix(xgb_scoring)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f00904f5910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0055383850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(steps, xgb_scoring.mean(axis = 1), marker='.', label='XGBoost')\n",
    "pylab.grid(True)\n",
    "pylab.xlabel('step')\n",
    "pylab.ylabel('r2')\n",
    "pylab.title('R2 score')\n",
    "pylab.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5\n",
    "\n",
    "Сравните получаемое с помощью градиентного бустинга качество с качеством работы линейной регрессии. \n",
    "\n",
    "Для этого обучите `LinearRegression` из `sklearn.linear_model` (с параметрами по умолчанию) на обучающей выборке и оцените для прогнозов полученного алгоритма на тестовой выборке `RMSE`. Полученное качество - ответ в **пункте 5**. \n",
    "\n",
    "В данном примере качество работы простой модели должно было оказаться хуже, но не стоит забывать, что так бывает не всегда. В заданиях к этому курсу вы еще встретите пример обратной ситуации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
